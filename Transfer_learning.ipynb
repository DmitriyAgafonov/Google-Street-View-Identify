{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b7ba551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e6c6701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipynb\n",
      "  Downloading ipynb-0.5.1-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: ipynb\n",
      "Successfully installed ipynb-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b90b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.CNN import check_grey_imgs, transform_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57be60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to data\n",
    "\n",
    "TRAIN_LABELS_PATH = './data/street-view-getting-started-with-julia/TrainLabelsExtended.csv'\n",
    "TRAIN_IMG_PATH = './data/street-view-getting-started-with-julia/trainResized/'\n",
    "TEST_IMG_PATH = './data/street-view-getting-started-with-julia/testResized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2656a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_LABELS_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03941517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f1ccef9",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c90c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_enc = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57c65e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5944</td>\n",
       "      <td>H</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11109</td>\n",
       "      <td>Y</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11177</td>\n",
       "      <td>Y</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1380</td>\n",
       "      <td>I</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9773</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18737</th>\n",
       "      <td>10112</td>\n",
       "      <td>K</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18738</th>\n",
       "      <td>4076</td>\n",
       "      <td>S</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18739</th>\n",
       "      <td>2999</td>\n",
       "      <td>S</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18740</th>\n",
       "      <td>5404</td>\n",
       "      <td>h</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18741</th>\n",
       "      <td>4203</td>\n",
       "      <td>o</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18742 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Class  Label\n",
       "0       5944     H     17\n",
       "1      11109     Y     34\n",
       "2      11177     Y     34\n",
       "3       1380     I     18\n",
       "4       9773     F     15\n",
       "...      ...   ...    ...\n",
       "18737  10112     K     20\n",
       "18738   4076     S     28\n",
       "18739   2999     S     28\n",
       "18740   5404     h     43\n",
       "18741   4203     o     50\n",
       "\n",
       "[18742 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc = LabelEncoder()\n",
    "train_df_enc['Label'] = label_enc.fit_transform(train_df_enc['Class'])\n",
    "train_df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e5cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_labels = dict(enumerate(label_enc.classes_))\n",
    "# replaced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e51b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8554623f",
   "metadata": {},
   "source": [
    "### Load transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e260e0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_train_', 'X_test_', 'y_train_', 'y_test_']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data = np.load('transformed_data.npz')\n",
    "transformed_data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8de74a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = transformed_data[transformed_data.files[0]] \n",
    "X_test_ = transformed_data[transformed_data.files[1]]\n",
    "y_train_ = transformed_data[transformed_data.files[2]].flatten()\n",
    "y_test_ = transformed_data[transformed_data.files[3]].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f736743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67664073",
   "metadata": {},
   "source": [
    "### Resize imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "41441210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(original_arr):\n",
    "    new_arr = np.empty([original_arr.shape[0]] + [32, 32, 3])\n",
    "    n = 0\n",
    "    for i in original_arr:\n",
    "        \n",
    "        new_i = cv2.resize(i, (32, 32), interpolation = cv2.INTER_LANCZOS4)\n",
    "        new_arr[n] = new_i\n",
    "        \n",
    "        n+=1\n",
    "        \n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4fef3fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 32, 32, 3)\n",
      "(3749, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_res = resize_img(X_train_)\n",
    "X_test_res = resize_img(X_test_)\n",
    "\n",
    "print(X_train_res.shape)\n",
    "print(X_test_res.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6578ffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(X_train_res[6]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4f054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eb5a646",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf4b0fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train_))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d331b7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "vgg_model.trainable = False\n",
    "\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a49beccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ = keras.layers.Input(shape=(20, 20, 3), name='image_input')\n",
    "# resize = keras.layers.Resizing(32, 32)(input_)\n",
    "input_ = keras.layers.Input(shape=(32, 32, 3), name='image_input')\n",
    "\n",
    "x = vgg_model(inputs = input_)\n",
    "\n",
    "x = keras.layers.Flatten(name='flatten')(x)\n",
    "x = keras.layers.Dense(128, activation='relu', name='fc1')(x)\n",
    "# x = keras.layers.Dense(254, activation='relu', name='fc2')(x)\n",
    "output_ = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = keras.Model(input_, output_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e0b7f248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 62)                7998      \n",
      "=================================================================\n",
      "Total params: 14,788,350\n",
      "Trainable params: 73,662\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "91c1ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7e2789cb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14993 samples, validate on 3749 samples\n",
      "Epoch 1/10\n",
      " 1632/14993 [==>...........................] - ETA: 1:57 - loss: 4.1151 - accuracy: 0.0338"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-590c650b876e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m history = model.fit(X_train_res, y_train_, epochs=10, \n\u001b[1;32m----> 2\u001b[1;33m                    validation_data=(X_test_res, y_test_))\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggleenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggleenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggleenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggleenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggleenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggleenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggleenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggleenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggleenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggleenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggleenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_res, y_train_, epochs=10, \n",
    "                   validation_data=(X_test_res, y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b60a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1b5a2ac",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c424d568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "10d7c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet50(weights= 'imagenet', include_top=False, input_shape= (32, 32, 3))\n",
    "resnet_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5c6cd5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = resnet_model.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "predictions =  keras.layers.Dense(num_classes, activation= 'softmax')(x)\n",
    "model = keras.Model(inputs = resnet_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b478911f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2048)         0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 62)           127038      dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,714,750\n",
      "Trainable params: 127,038\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6ba13297",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "600acf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14993 samples, validate on 3749 samples\n",
      "Epoch 1/3\n",
      "14993/14993 [==============================] - 312s 21ms/sample - loss: 4.0273 - accuracy: 0.1325 - val_loss: 4.1290 - val_accuracy: 0.0131\n",
      "Epoch 2/3\n",
      "14993/14993 [==============================] - 137s 9ms/sample - loss: 3.9151 - accuracy: 0.2498 - val_loss: 4.1276 - val_accuracy: 0.0149\n",
      "Epoch 3/3\n",
      "14993/14993 [==============================] - 139s 9ms/sample - loss: 3.8690 - accuracy: 0.2935 - val_loss: 4.1348 - val_accuracy: 0.0157\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_res, y_train_, epochs=3, \n",
    "                   validation_data=(X_test_res, y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a234a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80524962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5c192d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec1231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8bcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
